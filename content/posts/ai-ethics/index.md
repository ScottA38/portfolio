---
title: "Can principles of Social Responsbility make A.I safer?"
draft: true
---

# A stimulating read

Not so long ago, I stumbled across a Deeply stimulating read on Time Magazine's website - a piece entitled 'AI Engineers Need Their Own Hippocratic Oath. Hereâ€™s What It Should Say" authored [Dr. Dana Suskind](https://surgery.uchicago.edu/faculty/dana-l-suskind-md), a researcher in Neurology.

Despite it's brevity, this concept of this article had the quality of mental adhesivel, and in the coming weeks it would plant the seed for regular rumination and cogitation, the result of which is what you read here today.

## A jerk of the knee

From the outset, I desperately wanted to peg Dr. Dana Suskind's idea down to naievete and dismiss it out of hand. With many years of professional Software experience behind me, I had borne personal witness to the extent by which six-figure salaries, ego-driven competition between employees and manic, work-obsessesed lifestyles could distort and shift peoples' natural sensibilities of balance.

A.I as a sector is well-known for it's near-exponentional growth rate, relentless controversy the public sphere and astronomical salary expenditure in order to hire subject-matter specialists. As a result, when I conjured up a mental image of a professional within one of the most coveted professions of the 21st century voluntarily stepping on-stage to swear to do good, be transparent and protect the humanity at all costs (including their paycheck), the image played something like a parody.


...the image stuck. And stayed there.

The family and friends I approached roared passionate about how wonderful they thought the idea was, yet I still didn't see it's viability.

### Dusting off the cobwebs

Imbued with a fresh sense of optimism for new horizons this year, I tapped in a _tentatively-optimistic_ request for the search terms "A.I hippocratic oath" in my browser this morning, with encouraging results.

Almost immediately, my screen lit up enthusiastically with results - some decisive rumblings in the aether had emerged around A.I Social Responsibility. 

The reverberations of this idea were so strong that the concept had already transmuted itself into other domains like Law, with the Washington University Law Review publishing a [dedicated whitepaper proposal ](https://wustllawreview.org/wp-content/uploads/2025/03/12_Sharma_FINAL-v.2.0-1.pdf) detailing the potential benefits of professionalisation within the field of A.I.

The paper in question extolled the benefits of Professionalisation within other industries, for instance professionalisation initiatives within the occupation of Accountancy, where  Emergency Paramedic roles, which profited EMTs detailed education on cultural sensitivity and from   aving been published about the t and well-formed that a contemplation had even overlapped into other domains,  

 I had departed the topic there had been some very poignant rumblings to

<!-- 
to for technology product development played that is  elite professional members belonging to what has to be insiduous the motives of people within the indutry could be in terms of money-centric thinking and ego-driven intellectualism.


o my first instinct was to put this idea down to naievete and swiftly move on. Like a barnacle stuck to the side of a boat, however, this 
 -->
My self-entitled opinion based upon my knowledge of the Software Engineering industry told me gave me the insight to scoff Despite the article's relatively detached conjecture about A.I as a concept, the analogy presented was a powerful one, and it stuck with me for weeks to come.

In the coming days and weeks, I would float this trivial musing to friends and family. To my surprise, the concept of drawing parallels with stu


In subsequent
- Discovered Time piece about 'A.I Engineer Hippocratic Oath https://time.com/7312350/ai-engineers-need-hippocratic-oath/
    - Presenting 'Social Responsibility principles' as ethical
- Discussed with family & friends
    - Interesting results
- My existing experience with Open source projects for existing Software show how community-driven approaches may be chronically underrepresented 

## Going deeper

- Washington University of Law has [published an official paper](https://wustllawreview.org/wp-content/uploads/2025/03/12_Sharma_FINAL-v.2.0-1.pdf) about A.I hippocratic oath

## Big Companies

-  A.I Engineers don't likely hold much power individually to make changes to lengthy and astronomically expensive R&D processes
- Social responsibility principles usually rely on forms of intrinsic motivation: what ideas of intrinsic motivation can be made here, except for non-IT population ordering them to 'clean up after themselves'?
- How to delineate causation if issue is already a known issue within society?
- i.e: a community drive to keep a neighbourhood clean might by younger residents' care and concern for elderly residents, or a sense of people connecting to raise the collective self-esteem of the community within the neighbourhood - these are intrinsic motivations
- Need to consider what might be the motivations of A.I Engineers to approach the industry in the first place
- Lots of technology developers are highly motivated by money, in which case safety frameworks are seen as 'red tape'
- In my experience of Software Engineers encounter a lot of red tape. (open question to audience) - Do any of these proposals actually provide a compelling reason for A.I Engineers to talk and interact with each other regarding topics of ethics and safety which aren't implicitly labelling them or the work they do as evil or scary? 

## Official reports

- A.I may have factors which have the potential to cause harm intrinsically
- 

## Existing safeguarding mechanisms

- Google's [SAIF](https://www.saif.google/secure-ai-framework/risks)
    - Data poisoning
        - Backdoor attacks in training data